# -*- coding: utf-8 -*-
"""Twitter trends collection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aOYrz3Uf-FJ1nA_5tIaZiT-Ie5Dp8_Jg

# Steps:

    1. Get trending topics using trends_avalible() method from tweepy.
    2. save those trending topics to json and after that create a list of trneding topics names
    3. Now use query method to get those topics tweets and save them in CSV with there query.

# Collecting trending topics

**reference** : https://medium.com/analytics-vidhya/how-to-get-trending-tweets-in-any-country-with-python-and-tweepy-af2bfe760251

## 1. Libray importing
"""


import tweepy
import os
import json
import sys
import datetime
import pandas as pd

"""## 2. Api keys and tokens"""

def authenticate_with_secrets():
    CONSUMER_KEY = 'bfGWM7G7WylwHnayWAsv1mmHS'
    CONSUMER_SECRET = 'jELrN8U7agcSlDw0k4nWilRiO2etj0DGSEwkWlTGI4wWqCBlVZ'
    ACCESS_TOKEN = '1170647549520121856-hdfu8cmphlXjl5acd21i7rUCf36HCS'
    ACCESS_TOKEN_SECRET = 'Llpcdz1vkxhbpbzhAYmZILuG5MlgtxGl9la0J4mKUSNTy'

    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
    api = tweepy.API(auth)

    return api

"""## 4. Collecting trending topics"""

def trending_topics(api):
    #Avalible locations
    loc = api.trends_available()
    # writing a JSON file that has the available trends around the world
    with open("avalible_locs.json", "w") as wp:
        return wp.write(json.dumps(loc, indent=1))
        
        
        
def get_last_tweet_ids():
    with open("avalible_locs.json", "r") as file:
        return json.load(file)
        
def update_last_tweet_ids(last_tweet_ids):
    with open("avalible_locs.json", "w") as file:
        json.dump(last_tweet_ids, file)
        
        
"""# Saving trending topics """

def saving_trending_topics(json_file_path):
    #loding the dataset
    file = open(json_file_path)
    json_data = json.load(file)
    #saving the trending topics
    trending_topics = []
    for i in range(len(json_data)):
        if json_data[i]['name']:
            trending_topics.append(json_data[i]['name'])
                                                
    return trending_topics
                                               
"""# Collecting trending tweets"""

def trending_tweets(api, topics):
    tweets = api.search(q=topics, language='en')
    return tweets

def process_raw_tweet(tweet):
    processed_tweet = {}
    processed_tweet['id'] = tweet.id
    processed_tweet['username'] = tweet.user.screen_name
    processed_tweet['tweet_text'] = tweet.text
    processed_tweet['retweets'] = tweet.retweet_count
    processed_tweet['location'] = tweet.user.location
    processed_tweet['created_at'] = tweet.created_at
    return processed_tweet

def upload_tweets(tweets, file_path):
    df = pd.DataFrame(tweets)
    if not os.path.exists(file_path):
        os.makedirs(file_path)
        return df.to_csv(file_path)
    else: 
        return df.to_csv(file_path, mode='a', header=False)

def main():
    api = authenticate_with_secrets()
    file_path = trending_topics(api)                                            
    treding_topics = saving_trending_topics('avalible_locs.json')
    today_date = datetime.date.today()
    last_tweet_ids = get_last_tweet_ids()                                            
                                                
    for topic in treding_topics:
        file_path = 'data/' + str(today_date) '/' + topic + '/data.csv'
        processed_tweets = []
        tweets = trending_tweets(api, topic)
        if tweets:
            for tweet in tweets:
                processed_tweet = process_raw_tweet(tweet)
                processed_tweets.append(processed_tweet)
            upload_tweets(processed_tweets, file_path)
    update_last_tweet_ids(last_tweet_ids)
                                                
                                                
if __name__ == "__main__":
    main()
